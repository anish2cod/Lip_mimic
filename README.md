# Lip_Sync

Introduction :
  This projects aims to convert a short video with a person or a photo of a person into a video based on the audio provided, the generated video will have the lips of the person synced to the audio.

Behind the scence:
  This project takes help of pre trained model Wave2lip. The Wave2lip is a complete machine learning model for syncing lips movement with audio.

  In this project , I have made it easier for a youtube video to be synced based on audio file present in the system. Since the larger videos takes long time to sync, I have chosen certain interal of the video. It can be modified by chaning the start and end variables in the video trimming process.
  This entire file can be run safely in the colab without having to tweak much around the variables. In case of running it in other platforms just the content folder has to changed to the desired folder.There are some interactive codes written between to play audio and video which can safely removed if not need.
